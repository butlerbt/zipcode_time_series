{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 4 Project - Starter Notebook\n",
    "\n",
    "This notebook has been provided to you so that you can make use of the following starter code to help with the trickier parts of preprocessing the Zillow dataset. \n",
    "\n",
    "The notebook contains a rough outline the general order you'll likely want to take in this project. You'll notice that most of the areas are left blank. This is so that it's more obvious exactly when you should make use of the starter code provided for preprocessing. \n",
    "\n",
    "**_NOTE:_** The number of empty cells are not meant to infer how much or how little code should be involved in any given step--we've just provided a few for your convenience. Add, delete, and change things around in this notebook as needed!\n",
    "\n",
    "# Some Notes Before Starting\n",
    "\n",
    "This project will be one of the more challenging projects you complete in this program. This is because working with Time Series data is a bit different than working with regular datasets. In order to make this a bit less frustrating and help you understand what you need to do (and when you need to do it), we'll quickly review the dataset formats that you'll encounter in this project. \n",
    "\n",
    "## Wide Format vs Long Format\n",
    "\n",
    "If you take a look at the format of the data in `zillow_data.csv`, you'll notice that the actual Time Series values are stored as separate columns. Here's a sample: \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/df_head.png'>\n",
    "\n",
    "You'll notice that the first seven columns look like any other dataset you're used to working with. However, column 8 refers to the median housing sales values for April 1996, column 9 for May 1996, and so on. This This is called **_Wide Format_**, and it makes the dataframe intuitive and easy to read. However, there are problems with this format when it comes to actually learning from the data, because the data only makes sense if you know the name of the column that the data can be found it. Since column names are metadata, our algorithms will miss out on what dates each value is for. This means that before we pass this data to our ARIMA model, we'll need to reshape our dataset to **_Long Format_**. Reshaped into long format, the dataframe above would now look like:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/melted1.png'>\n",
    "\n",
    "There are now many more rows in this dataset--one for each unique time and zipcode combination in the data! Once our dataset is in this format, we'll be able to train an ARIMA model on it. The method used to convert from Wide to Long is `pd.melt()`, and it is common to refer to our dataset as 'melted' after the transition to denote that it is in long format. \n",
    "\n",
    "# Helper Functions Provided\n",
    "\n",
    "Melting a dataset can be tricky if you've never done it before, so you'll see that we have provided a sample function, `melt_data()`, to help you with this step below. Also provided is:\n",
    "\n",
    "* `get_datetimes()`, a function to deal with converting the column values for datetimes as a pandas series of datetime objects\n",
    "* Some good parameters for matplotlib to help make your visualizations more readable. \n",
    "\n",
    "Good luck!\n",
    "\n",
    "\n",
    "# Step 1: Load the Data/Filtering for Chosen Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/raw/zillow_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_zipcode(df, index):\n",
    "    \"\"\"This function pulls the data for one zipcode at a time and retuns a DataFrame for using in Prophet.\"\"\"\n",
    "    series = df.iloc[index]\n",
    "    series_data = series.iloc[7:]\n",
    "    df_series = pd.DataFrame(series_data.values, index = series_data.index, columns = ['y'])\n",
    "    df_series.index = pd.to_datetime(df_series.index, yearfirst = True, format = '%Y-%m')\n",
    "    df_series['ds'] = df_series.index\n",
    "    df_series.reset_index(drop = True, inplace = True)\n",
    "    df_series['y'] = df_series['y'].astype('int64')\n",
    "    return df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_zipcode(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need helper function for zipcode\n",
    "def get_zipcode(df, index):\n",
    "    \"\"\"This function extracts the zipcode from the dataframe at the index. Useful in constructing data dictionanry\n",
    "    later.\"\"\"\n",
    "    zipcode = df['RegionName'].iloc[index]\n",
    "    return zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_zipcode(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull first zip code from df\n",
    "series_84654 = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the meta data for the zip code\n",
    "df_84654_data = series_84654.iloc[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the series that no longer has the first 7 lines, and put it in a DF\n",
    "df_84654 = pd.DataFrame(df_84654_data.values, index=df_84654_data.index, columns=['y'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index as date time format\n",
    "df_84654.index = pd.to_datetime(df_84654.index,yearfirst=True, format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654['ds']=df_84654.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654['y'] = df_84654['y'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654.y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prophet_analysis(df):\n",
    "    \"\"\"This function instantiates a Prophet model, fits it to the DataFrame, and predicts values which are returned in \n",
    "    a forecast Dataframe.\"\"\"\n",
    "    m = Prophet(seasonality_mode='multiplicative', interval_width=0.95)\n",
    "    m.fit(df)\n",
    "    future = m.make_future_dataframe(60, freq = 'M')\n",
    "    forecast = m.predict(future)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prophet_analysis(one_zipcode(df, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Prophet(seasonality_mode='multiplicative', interval_width=0.95)\n",
    "m.fit(df_84654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(60, freq='M')\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_recent_value(df):\n",
    "    '''\n",
    "    Finds the most recent median home value for use in future percent calculation.\n",
    "    '''\n",
    "    i = -1\n",
    "    while np.isnan(df.iloc[i]['y']):\n",
    "        i -= 1\n",
    "\n",
    "    return df.iloc[i]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(df, forecast):\n",
    "    \"\"\"This function combines the original dataframe with data from one zipcode and the forecasted values from the\n",
    "    Prophet analysis into a single DataFrame. It also adds new columns for percent change from the last value in\n",
    "    the original dataframe and the estimated gross profit.\"\"\"\n",
    "    forecast.rename(columns={'yhat': 'y'}, inplace = True)\n",
    "    forecast_subset = forecast[forecast['ds']>'2018-04-01'][['ds','y', 'yhat_lower', 'yhat_upper']]\n",
    "    df_appended = df.append(forecast_subset, sort = True)\n",
    "    df_appended['pct_change'] = ((df_appended['y']-most_recent_value(df))/most_recent_value(df))*100\n",
    "    df_appended['gross_profit'] = (df_appended['y']-most_recent_value(df))\n",
    "    return df_appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dataframes(one_zipcode(df, 5), Prophet_analysis(one_zipcode(df, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.rename(columns={\"yhat\": \"y\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_subset = forecast[forecast['ds']>'2018-04-01'][['ds','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654_appended = df_84654.append(forecast_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654_appended['pct_change'] = ((df_84654_appended['y']-most_recent_value(df_84654))/most_recent_value(df_84654))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654_appended['net_profit'] = (df_84654_appended['y']-most_recent_value(df_84654))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654_appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(df, zipcode):\n",
    "    \"\"\"This function returns a summary dictionary from the combined dataframe for a given zipcode. This dictionary\n",
    "    can be appended to a list that will be used to make a final dataframe.\"\"\"\n",
    "    pct_change_1year = df.loc[(df['ds']>'2019-03-31') \n",
    "                                       & (df['ds']<'2019-05-01')]['pct_change'].values[0]\n",
    "    gross_profit_1year = df.loc[(df['ds']>'2019-03-31') \n",
    "                                       & (df['ds']<'2019-05-01')]['gross_profit'].values[0]\n",
    "    pct_change_5year = df.loc[(df['ds']>='2023-03-31')]['pct_change'].values[0]\n",
    "    gross_profit_5year = df.loc[(df['ds']>='2023-03-31')]['gross_profit'].values[0]\n",
    "    estimate_1year = df.loc[(df['ds']>'2019-03-31') \n",
    "                                       & (df['ds']<'2019-05-01')]['y'].values[0]\n",
    "    upper_1year = df.loc[(df['ds']>'2019-03-31') \n",
    "                                       & (df['ds']<'2019-05-01')]['yhat_upper'].values[0]\n",
    "    lower_1year = df.loc[(df['ds']>'2019-03-31') \n",
    "                                       & (df['ds']<'2019-05-01')]['yhat_lower'].values[0]\n",
    "    estimate_5year = df.loc[(df['ds']>='2023-03-31')]['y'].values[0]\n",
    "    upper_5year = df.loc[(df['ds']>='2023-03-31')]['yhat_upper'].values[0]\n",
    "    lower_5year = df.loc[(df['ds']>='2023-03-31')]['yhat_lower'].values[0]\n",
    "    zipcode_dict = {'Zipcode': zipcode, \n",
    "                    'estimate_1year': estimate_1year,\n",
    "                    'upper_1year': upper_1year,\n",
    "                    'lower_1year': lower_1year,\n",
    "                    'pct_change_1year': pct_change_1year,\n",
    "                    'estimate_5year': estimate_5year,\n",
    "                    'upper_5year': upper_5year,\n",
    "                    'lower_5year': lower_5year,\n",
    "                    'gross_profit_1year': gross_profit_1year, \n",
    "                    'pct_change_5year': pct_change_5year, \n",
    "                    'gross_profit_5year': gross_profit_5year}\n",
    "    return zipcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dict(combine_dataframes(one_zipcode(df, 5), Prophet_analysis(one_zipcode(df, 5))), get_zipcode(df, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = [{'Zipcode': series_84654['RegionName'], \n",
    " 'pct_change_1year': pct_change_1year, \n",
    " 'net_profit_1year': net_profit_1year, \n",
    " 'pct_change_5year': pct_change_5year, \n",
    " 'net_profit_5year': net_profit_5year},\n",
    "         {'Zipcode': series_84654['RegionName'], \n",
    " 'pct_change_1year': pct_change_1year, \n",
    " 'net_profit_1year': net_profit_1year, \n",
    " 'pct_change_5year': pct_change_5year, \n",
    " 'net_profit_5year': net_profit_5year}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654_appended.iloc[df_84654_appended[(df_84654_appended['ds']>'2019-03-31') \n",
    "                                         & (df_84654_appended['ds']<'2019-05-01')].index]['pct_change'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_1year = df_84654_appended.loc[(df_84654_appended['ds']>'2019-03-31') \n",
    "                                       & (df_84654_appended['ds']<'2019-05-01')]['pct_change'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_profit_1year = df_84654_appended.loc[(df_84654_appended['ds']>'2019-03-31') \n",
    "                                       & (df_84654_appended['ds']<'2019-05-01')]['net_profit'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_5year = df_84654_appended.loc[(df_84654_appended['ds']>='2023-03-31') \n",
    "                                       ]['pct_change'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_profit_5year = df_84654_appended.loc[(df_84654_appended['ds']>='2023-03-31') \n",
    "                                       ]['net_profit'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df = pd.DataFrame(columns=['RegionID','RegionName','City','State','Metro','CountyName','y','pct_change','net_profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_row = pd.DataFrame(df_84654_appended[(df_84654_appended['ds']>'2019-03-31') & (df_84654_appended['ds']<'2019-05-01') ][['y','pct_change','net_profit']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df = one_year_df.append(df_84654_appended[(df_84654_appended['ds']>'2019-03-31') & (df_84654_appended['ds']<'2019-05-01') ][['y','pct_change','net_profit']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df.join(pd.DataFrame(series_84654), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_84654[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_84654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetimes(df):\n",
    "    return pd.to_datetime(df.columns.values[1:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# NOTE: if you visualizations are too cluttered to read, try calling 'plt.gcf().autofmt_xdate()'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Reshape from Wide to Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'City', 'State', 'Metro', 'CountyName'], var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: ARIMA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zipcode)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
